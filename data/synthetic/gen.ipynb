{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 일반"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         X1        X2        X3        T1        T2         Y\n",
      "0 -0.274246  0.114029 -0.222736 -0.197550 -0.141564 -0.482924\n",
      "1  0.338196 -0.670267  1.082468  0.208837  0.687798  2.986315\n",
      "2  0.270876 -0.427974  0.622267 -0.047693  0.143983  0.819783\n",
      "3 -0.018729 -0.227047  0.135349  0.051812  0.280557  0.716724\n",
      "4 -0.232718  0.525012 -0.811217 -0.147677 -0.416117 -1.942434\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터 개수 설정\n",
    "n_samples = 10000\n",
    "\n",
    "# 외생 변수 Z 생성 (latent, 최종 데이터에는 포함되지 않음)\n",
    "np.random.seed(42)\n",
    "\n",
    "Z = np.random.uniform(-1, 1, n_samples)\n",
    "\n",
    "# X1, X2, X3 생성 (Z에 선형 관계와 노이즈 추가)\n",
    "X1 = 0.5 * Z + np.random.normal(0, 0.1, n_samples)\n",
    "X2 = -0.7 * Z + np.random.normal(0, 0.1, n_samples)\n",
    "X3 = 1.2 * Z + np.random.normal(0, 0.1, n_samples)\n",
    "\n",
    "# T1, T2 생성 (Z 및 T1에 선형 관계와 노이즈 추가)\n",
    "T1 = 0.3 * Z + np.random.normal(0, 0.1, n_samples)\n",
    "T2 = 0.8 * T1 + 0.5 * Z + np.random.normal(0, 0.1, n_samples)\n",
    "\n",
    "# Y 생성 (Z, T2에 선형 관계와 노이즈 추가)\n",
    "Y = 1.5 * Z + 2.0 * T2 + np.random.normal(0, 0.2, n_samples)\n",
    "\n",
    "# 데이터 프레임 생성 (Z는 포함시키지 않음)\n",
    "data = pd.DataFrame({\n",
    "    'X1': X1,\n",
    "    'X2': X2,\n",
    "    'X3': X3,\n",
    "    'T1': T1,\n",
    "    'T2': T2,\n",
    "    'Y': Y\n",
    "})\n",
    "\n",
    "# 데이터 확인\n",
    "print(data.head())\n",
    "data.to_csv('synthetic.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시계열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Z        X1        X2        X3        T1        T2         Y\n",
      "0  0.516732  0.267814 -0.272633  0.578618  0.197903  0.458707  0.129085\n",
      "1  0.469930  0.201121 -0.339048  0.739961  0.140373  0.301187 -0.446921\n",
      "2  0.462342  0.210427 -0.241025  0.659842  0.396955  0.454402 -0.301617\n",
      "3  0.430938  0.032348 -0.245854  0.702234  0.227834  0.370832 -0.226085\n",
      "4  0.395424  0.327843 -0.109247  0.322533  0.209899  0.279360 -0.096919\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "n_series = 1000  # 시계열 데이터 개수\n",
    "n_length = 5     # 각 시계열의 길이\n",
    "\n",
    "# 파라미터 설정\n",
    "phi = 0.9\n",
    "# np.random.seed(42)\n",
    "\n",
    "# 시계열 데이터 구조 초기화\n",
    "Z = np.zeros((n_series, n_length))\n",
    "X1 = np.zeros((n_series, n_length))\n",
    "X2 = np.zeros((n_series, n_length))\n",
    "X3 = np.zeros((n_series, n_length))\n",
    "T1 = np.zeros((n_series, n_length))\n",
    "T2 = np.zeros((n_series, n_length))\n",
    "Y = np.zeros((n_series, n_length))\n",
    "\n",
    "for i in range(n_series):\n",
    "    Z[i, 0] = np.random.exponential(1)  # 초기값을 양수로 설정 (지수 분포)\n",
    "    for t in range(1, n_length):\n",
    "        Z[i, t] = phi * Z[i, t-1] + np.random.exponential(0.1)  # 양수로 제한\n",
    "\n",
    "\n",
    "# 나머지 변수 계산\n",
    "for i in range(n_series):\n",
    "    for t in range(n_length):\n",
    "        X1[i, t] = 0.5 * Z[i, t] + np.random.normal(0, 0.1)\n",
    "        X2[i, t] = -0.7 * Z[i, t] + np.random.normal(0, 0.1)\n",
    "        X3[i, t] = 1.2 * Z[i, t] + np.random.normal(0, 0.1)\n",
    "        T1[i, t] = 0.3 * Z[i, t] + np.random.normal(0, 0.1)\n",
    "        T2[i, t] = 0.8 * T1[i, t] + 0.3 * Z[i, t] + np.random.normal(0, 0.1)\n",
    "        # Y[i, t]를 시간에 따라 감소하는 선형 트렌드를 추가하여 계산\n",
    "        decay_factor = 1.0 - 0.2 * t  # 감소 계수, 시간에 따라 감소\n",
    "        Y[i, t] = (0.7 * Z[i, t] - 1.3 * T2[i, t] + np.random.normal(0, 0.2)) #* decay_factor\n",
    "\n",
    "\n",
    "# 데이터 프레임으로 변환\n",
    "data_frames = [pd.DataFrame({\n",
    "    'Z': Z[i, :],\n",
    "    'X1': X1[i, :],\n",
    "    'X2': X2[i, :],\n",
    "    'X3': X3[i, :],\n",
    "    'T1': T1[i, :],\n",
    "    'T2': T2[i, :],\n",
    "    'Y': Y[i, :]\n",
    "}) for i in range(n_series)]\n",
    "\n",
    "# 첫 번째 시계열 데이터 확인\n",
    "print(data_frames[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 더 우리와 같은 setting (T1, T2 가 seq별로 고정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Z        X1        X2        X3        X4        T1        T2  \\\n",
      "0  0.233453  0.129841 -0.163832  0.293045  0.972370  0.019833  0.090322   \n",
      "1  0.292146  0.150837 -0.346751  0.298301  1.072382  0.019833  0.090322   \n",
      "2  0.277541  0.101334 -0.231111  0.351270  1.045465  0.019833  0.090322   \n",
      "3  0.391738  0.282074 -0.328807  0.501929  1.134855  0.019833  0.090322   \n",
      "4  0.353439  0.137889 -0.266856  0.418021  1.098971  0.019833  0.090322   \n",
      "\n",
      "          P         Y  \n",
      "0  1.045998  5.496728  \n",
      "1  1.087084  4.450730  \n",
      "2  1.076860  3.363646  \n",
      "3  1.156798  2.286786  \n",
      "4  1.129988  1.129988  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "n_series = 1000  # 시계열 데이터 개수\n",
    "n_length = 5     # 각 시계열의 길이\n",
    "\n",
    "# 파라미터 설정\n",
    "phi = 0.9\n",
    "\n",
    "# 시계열 데이터 구조 초기화\n",
    "Z = np.zeros((n_series, n_length))\n",
    "X1 = np.zeros((n_series, n_length))\n",
    "X2 = np.zeros((n_series, n_length))\n",
    "X3 = np.zeros((n_series, n_length))\n",
    "X4 = np.zeros((n_series, n_length))\n",
    "T1 = np.zeros((n_series, n_length))\n",
    "T2 = np.zeros((n_series, n_length))\n",
    "P = np.zeros((n_series, n_length))\n",
    "Y = np.zeros((n_series, n_length))\n",
    "\n",
    "for i in range(n_series):\n",
    "    Z[i, 0] = np.random.exponential(1)  # 초기값을 양수로 설정 (지수 분포)\n",
    "    for t in range(1, n_length):\n",
    "        Z[i, t] = phi * Z[i, t-1] + np.random.exponential(0.05)  # 양수로 제한\n",
    "\n",
    "for i in range(n_series):\n",
    "    # T1과 T2 계산을 한 번만 수행하고 모든 t에 대해 같은 값을 사용\n",
    "    T1[i, :] = 0.3 * Z[i, 0] + np.random.normal(0, 0.05)  # T1 초기화\n",
    "    T2[i, :] = 0.8 * T1[i, 0] + 0.3 * Z[i, 0] + np.random.normal(0, 0.05)  # T2 초기화\n",
    "    \n",
    "    for t in range(n_length):\n",
    "        X1[i, t] = 0.5 * Z[i, t] + np.random.normal(0, 0.05)\n",
    "        X2[i, t] = -0.7 * Z[i, t] + np.random.normal(0, 0.05)\n",
    "        X3[i, t] = 1.2 * Z[i, t] + np.random.normal(0, 0.05)\n",
    "        X4[i, t] = 0.2 * Z[i, t] + np.random.normal(0, 0.05) + 1\n",
    "        # Y[i, t]를 시간에 따라 감소하는 선형 트렌드를 추가하여 계산\n",
    "        # decay_factor = 1.0 - 0.2 * t  # 감소 계수, 시간에 따라 감소\n",
    "        P[i, t] = max(0, (0.7 * Z[i, t] - 1.3 * T2[i, 0] ) + 1) #* decay_factor  # T2[i, 0] 사용\n",
    "\n",
    "for i in range(n_series):\n",
    "    for j in range(n_length):\n",
    "        Y[i, j] = np.sum(P[i, j:n_length])  # j부터 n_length까지의 합\n",
    "\n",
    "# 데이터 프레임으로 변환\n",
    "data_frames = [pd.DataFrame({\n",
    "    'Z': Z[i, :],\n",
    "    'X1': X1[i, :],\n",
    "    'X2': X2[i, :],\n",
    "    'X3': X3[i, :],\n",
    "    'X4': X4[i, :],\n",
    "    'T1': T1[i, :],\n",
    "    'T2': T2[i, :],\n",
    "    'P': P[i, :],\n",
    "    'Y': Y[i, :]\n",
    "}) for i in range(n_series)]\n",
    "\n",
    "# 첫 번째 시계열 데이터 확인\n",
    "print(data_frames[0])\n",
    "\n",
    "with open('synthetic_ts.pkl', 'wb') as f:\n",
    "    pickle.dump(data_frames, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data_frames):\n",
    "        # Convert each dataframe column into a numpy array and then into a tensor\n",
    "        self.X1 = torch.tensor(np.array([df['X1'].values for df in data_frames]), dtype=torch.float32)\n",
    "        self.X2 = torch.tensor(np.array([df['X2'].values for df in data_frames]), dtype=torch.float32)\n",
    "        self.X3 = torch.tensor(np.array([df['X3'].values for df in data_frames]), dtype=torch.float32)\n",
    "        self.X4 = torch.tensor(np.array([df['X4'].values for df in data_frames]), dtype=torch.float32)\n",
    "        self.T1 = torch.tensor(np.array([df['T1'].values for df in data_frames]), dtype=torch.float32)\n",
    "        self.T2 = torch.tensor(np.array([df['T2'].values for df in data_frames]), dtype=torch.float32)\n",
    "        self.P = torch.tensor(np.array([df['P'].values for df in data_frames]), dtype=torch.float32)\n",
    "        self.Y = torch.tensor(np.array([df['Y'].values for df in data_frames]), dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the total length of the dataset\n",
    "        return len(self.Y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Return the tensors at the specific index\n",
    "        x1 = self.X1[idx]\n",
    "        x2 = self.X2[idx]\n",
    "        x3 = self.X3[idx]\n",
    "        x4 = self.X4[idx]\n",
    "        y = torch.sum(self.P[idx])\n",
    "        t1 = self.T1[idx]\n",
    "        t2 = self.T2[idx]\n",
    "        t = torch.cat((t1.unsqueeze(0), t2.unsqueeze(0)), dim=0)\n",
    "        index_tensor = torch.tensor([0, 1, 2, 3, 4], dtype=torch.float)\n",
    "        x1_length = x1.shape[0]\n",
    "\n",
    "        return x1, x2, x3, x4, x1_length, y, index_tensor, torch.mean(t, dim=-1)\n",
    "\n",
    "# Load the dataset from a CSV file and convert it back to individual dataframes\n",
    "with open('synthetic_ts.pkl', 'rb') as f:\n",
    "    data_frames = pickle.load(f)\n",
    "    \n",
    "dataset = TimeSeriesDataset(data_frames)\n",
    "dataloader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "# 배치 데이터 처리 예시\n",
    "for x1, x2, x3, x4, x1_length, y, index_tensor, t in dataloader:\n",
    "    # print(x1, x2, x3, x4, x1_length, y, index_tensor, t)\n",
    "    print(x1.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/bubble3jh/anaconda3/envs/cet/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import dowhy\n",
    "from dowhy import CausalModel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import os\n",
    "import graphviz\n",
    "from causallearn.search.FCMBased.lingam.utils import make_dot\n",
    "from causallearn.search.FCMBased import lingam\n",
    "from causallearn.search.ConstraintBased.PC import pc\n",
    "from causallearn.search.ScoreBased.GES import ges\n",
    "from causallearn.search.HiddenCausal.GIN.GIN import GIN\n",
    "from causallearn.utils.GraphUtils import GraphUtils\n",
    "import dowhy.datasets\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "\n",
    "def make_graph(adjacency_matrix, labels=None):\n",
    "    idx = np.abs(adjacency_matrix) > 0.01\n",
    "    dirs = np.where(idx)\n",
    "    d = graphviz.Digraph(engine='dot')\n",
    "    names = labels if labels else [f'x{i}' for i in range(len(adjacency_matrix))]\n",
    "    for name in names:\n",
    "        d.node(name)\n",
    "    for to, from_, coef in zip(dirs[0], dirs[1], adjacency_matrix[idx]):\n",
    "        d.edge(names[from_], names[to], label=str(coef))\n",
    "    return d\n",
    "\n",
    "def str_to_dot(string):\n",
    "    '''\n",
    "    Converts input string from graphviz library to valid DOT graph format.\n",
    "    '''\n",
    "    graph = string.strip().replace('\\n', ';').replace('\\t','')\n",
    "    graph = graph[:9] + graph[10:-2] + graph[-1] # Removing unnecessary characters from string\n",
    "    return graph\n",
    "\n",
    "for tag in ['']:\n",
    "    data_path = f'synthetic.csv'\n",
    "    data = pd.read_csv(data_path)\n",
    "    # data = data.drop(['cut_date','diff_days'], axis=1)\n",
    "    labels = [f'{col}' for i, col in enumerate(data.columns)]\n",
    "    tag=f'{tag}_synthtetic'\n",
    "        \n",
    "    if not os.path.exists(f'./fig/pc{tag}.png'):\n",
    "        print(\"discovering with pc algorithm\")\n",
    "        data = data.to_numpy()\n",
    "\n",
    "        cg = pc(data)\n",
    "\n",
    "        # Visualization using pydot\n",
    "        pyd = GraphUtils.to_pydot(cg.G, labels=labels)\n",
    "        tmp_png = pyd.create_png(f=\"png\")\n",
    "        fp = io.BytesIO(tmp_png)\n",
    "        img = mpimg.imread(fp, format='png')\n",
    "        plt.axis('off')\n",
    "        plt.imshow(img)\n",
    "        plt.savefig(f'./fig/pc{tag}.png', dpi=300)\n",
    "\n",
    "\n",
    "    if not os.path.exists(f'./fig/ges{tag}.png'):\n",
    "        print(\"discovering with ges algorithm\")\n",
    "        # default parameters\n",
    "        Record = ges(data)\n",
    "\n",
    "        # Visualization using pydot\n",
    "        pyd = GraphUtils.to_pydot(Record['G'], labels=labels)\n",
    "        tmp_png = pyd.create_png(f=\"png\")\n",
    "        fp = io.BytesIO(tmp_png)\n",
    "        img = mpimg.imread(fp, format='png')\n",
    "        plt.axis('off')\n",
    "        plt.imshow(img)\n",
    "        plt.savefig(f'./fig/ges{tag}.png', dpi=300)\n",
    "\n",
    "\n",
    "    if not os.path.exists(f'./fig/lingam{tag}.png'):\n",
    "        print(\"discovering with lingam algorithm\")\n",
    "        model = lingam.ICALiNGAM()\n",
    "        model.fit(data)\n",
    "\n",
    "        \n",
    "        dot_object = make_dot(model.adjacency_matrix_, labels=labels)\n",
    "\n",
    "\n",
    "        # 'dot_object'는 'Digraph' 객체입니다.\n",
    "        dot_str = dot_object.source  # DOT 언어로 변환\n",
    "\n",
    "        # DOT 문자열을 사용하여 Source 객체 생성\n",
    "        dot_source = graphviz.Source(dot_str)\n",
    "\n",
    "        # 이미지 파일로 렌더링하여 저장\n",
    "        dot_source.render(f'./fig/lingam{tag}', format='png', engine='dot')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
